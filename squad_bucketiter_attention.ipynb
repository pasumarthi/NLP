{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squad_bucketiter_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cYgIeJLQL_U",
        "outputId": "bbfb3b8c-5701-44d8-ac23-0354ca2431bc"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fa8YWNsWWfl"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import math\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRiIqLc6cZmS"
      },
      "source": [
        "def read_squad(path):\n",
        "    path = Path(path)\n",
        "    with open(path, 'rb') as f:\n",
        "        squad_dict = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    for group in squad_dict['data']:\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                for answer in qa['answers']:\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(answer)\n",
        "\n",
        "    return contexts, questions, answers\n",
        "\n",
        "train_contexts, train_questions, train_answers = read_squad('/content/drive/MyDrive/END/session-9/train-v2.0.json')\n",
        "val_contexts, val_questions, val_answers = read_squad('/content/drive/MyDrive/END/session-9/dev-v2.0.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR8sRV-bcaTq",
        "outputId": "d284435a-b5fc-4c8e-d749-59c765292fbd"
      },
      "source": [
        "len(train_contexts), len(val_contexts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86821, 20302)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPfulUzUcdSk"
      },
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        gold_text = answer['text']\n",
        "        start_idx = answer['answer_start']\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        # sometimes squad answers are off by a character or two – fix this\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            answer['answer_end'] = end_idx\n",
        "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 1\n",
        "            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
        "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "            answer['answer_start'] = start_idx - 2\n",
        "            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
        "\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PwjDDaCAhI2",
        "outputId": "6b2b204b-b20a-41d0-c31a-59ab3c92c89a"
      },
      "source": [
        "train_answers[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_end': 286, 'answer_start': 269, 'text': 'in the late 1990s'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPbjt61WdDg6",
        "outputId": "1ea153ec-0ece-4ff7-d8d2-a67abe13c964"
      },
      "source": [
        "train_answers[0]\n",
        "ans_start, ans_end, ans = [], [], []\n",
        "for ii in range(len(train_answers)):\n",
        "  ans_start.append(train_answers[ii]['answer_start'])\n",
        "  ans_end.append(train_answers[ii]['answer_end'])\n",
        "  ans.append(train_answers[ii]['text'])\n",
        "print(len(ans_start), len(ans_end))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86821 86821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "UoA-1EeLcxyN",
        "outputId": "8c8b1f4f-3b0f-414d-81cc-9f12389112d2"
      },
      "source": [
        "df = pd.DataFrame(\n",
        "    {'context': train_contexts,\n",
        "     'question': train_questions,\n",
        "     'answer' : ans\n",
        "    })\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>in the late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>Houston, Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...               answer\n",
              "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  ...    in the late 1990s\n",
              "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  ...  singing and dancing\n",
              "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  ...                 2003\n",
              "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  ...       Houston, Texas\n",
              "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  ...           late 1990s\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5a7HgpIcPN-"
      },
      "source": [
        "Context = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Question = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Answer = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "\n",
        "fields = [('context', Context),('question', Question), ('answer',Answer)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oNnWon8swiS"
      },
      "source": [
        "example = [data.Example.fromlist([df.context[i],df.question[i],df.answer[i]], fields) for i in range(df.shape[0])] \n",
        "squadDataset = data.Dataset(example, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvfH1VPvqVtE"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "(train_data, valid_data) = squadDataset.split(split_ratio=[0.80, 0.2], random_state=random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoTPTeWKzmj5",
        "outputId": "51acf408-d43a-4ff7-80eb-67ffda127880"
      },
      "source": [
        "len(train_data),len(valid_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69457, 17364)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwdbSVlgwXOm"
      },
      "source": [
        "Context.build_vocab(train_data, min_freq = 2)\n",
        "Question.build_vocab(train_data, min_freq = 2)\n",
        "Answer.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgF_Fw_Fwk0B",
        "outputId": "955f9797-f554-4749-9094-7a1b971d002f"
      },
      "source": [
        "len(Context.vocab), len(Question.vocab), len(Answer.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97315, 21052, 18037)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa8IoZo1QD53",
        "outputId": "147c600e-0860-4b70-cd35-f98e26a633af"
      },
      "source": [
        "for i,ii in enumerate(valid_data):\n",
        "  print(ii.question)\n",
        "  print(ii.context)\n",
        "  print(ii.answer)\n",
        "  print(\"___________\")\n",
        "  if i == 4:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['What', 'is', 'the', 'literacy', 'rate', 'in', 'Israel', '?']\n",
            "['Israel', 'has', 'a', 'school', 'life', 'expectancy', 'of', '15.5', 'years', 'and', 'a', 'literacy', 'rate', 'of', '97.1', '%', 'according', 'to', 'the', 'United', 'Nations', '.', 'The', 'State', 'Education', 'Law', ',', 'passed', 'in', '1953', ',', 'established', 'five', 'types', 'of', 'schools', ':', 'state', 'secular', ',', 'state', 'religious', ',', 'ultra', 'orthodox', ',', 'communal', 'settlement', 'schools', ',', 'and', 'Arab', 'schools', '.', 'The', 'public', 'secular', 'is', 'the', 'largest', 'school', 'group', ',', 'and', 'is', 'attended', 'by', 'the', 'majority', 'of', 'Jewish', 'and', 'non', '-', 'Arab', 'pupils', 'in', 'Israel', '.', 'Most', 'Arabs', 'send', 'their', 'children', 'to', 'schools', 'where', 'Arabic', 'is', 'the', 'language', 'of', 'instruction', '.', 'Education', 'is', 'compulsory', 'in', 'Israel', 'for', 'children', 'between', 'the', 'ages', 'of', 'three', 'and', 'eighteen', '.', 'Schooling', 'is', 'divided', 'into', 'three', 'tiers', '–', 'primary', 'school', '(', 'grades', '1–6', ')', ',', 'middle', 'school', '(', 'grades', '7–9', ')', ',', 'and', 'high', 'school', '(', 'grades', '10–12', ')', '–', 'culminating', 'with', 'Bagrut', 'matriculation', 'exams', '.', 'Proficiency', 'in', 'core', 'subjects', 'such', 'as', 'mathematics', ',', 'the', 'Hebrew', 'language', ',', 'Hebrew', 'and', 'general', 'literature', ',', 'the', 'English', 'language', ',', 'history', ',', 'Biblical', 'scripture', 'and', 'civics', 'is', 'necessary', 'to', 'receive', 'a', 'Bagrut', 'certificate', '.', 'In', 'Arab', ',', 'Christian', 'and', 'Druze', 'schools', ',', 'the', 'exam', 'on', 'Biblical', 'studies', 'is', 'replaced', 'by', 'an', 'exam', 'on', 'Muslim', ',', 'Christian', 'or', 'Druze', 'heritage', '.', 'Christian', 'Arabs', 'are', 'one', 'of', 'the', 'most', 'educated', 'groups', 'in', 'Israel', '.', 'Maariv', 'have', 'describe', 'the', 'Christian', 'Arabs', 'sectors', 'as', '\"', 'the', 'most', 'successful', 'in', 'education', 'system', '\"', ',', 'since', 'Christian', 'Arabs', 'fared', 'the', 'best', 'in', 'terms', 'of', 'education', 'in', 'comparison', 'to', 'any', 'other', 'group', 'receiving', 'an', 'education', 'in', 'Israel', '.', 'Israeli', 'children', 'from', 'Russian', '-', 'speaking', 'families', 'have', 'a', 'higher', 'bagrut', 'pass', 'rate', 'at', 'high', '-', 'school', 'level', '.', 'Although', 'amongst', 'immigrant', 'children', 'born', 'in', 'the', 'FSU', ',', 'the', 'bagrut', 'pass', 'rate', 'is', 'highest', 'amongst', 'those', 'families', 'from', 'Western', 'FSU', 'states', 'of', 'Russia', ',', 'Ukraine', ',', 'Belarus', 'and', 'Moldova', '(', 'at', '62.6', '%', ')', ',', 'and', 'lower', 'amongst', 'those', 'from', 'Central', 'Asian', 'and', 'Caucasian', 'FSU', 'states', '.', 'In', '2003', ',', 'over', 'half', 'of', 'all', 'Israeli', 'twelfth', 'graders', 'earned', 'a', 'matriculation', 'certificate', '.']\n",
            "['97.1', '%']\n",
            "___________\n",
            "['What', 'size', 'rocket', 'was', 'being', 'developed', 'at', 'the', 'end', 'of', 'the', 'war', '?']\n",
            "['During', 'the', '1930s', 'solid', 'fuel', 'rockets', 'were', 'under', 'development', 'in', 'the', 'Soviet', 'Union', 'and', 'Britain', '.', 'In', 'Britain', 'the', 'interest', 'was', 'for', 'anti', '-', 'aircraft', 'fire', ',', 'it', 'quickly', 'became', 'clear', 'that', 'guidance', 'would', 'be', 'required', 'for', 'precision', '.', 'However', ',', 'rockets', ',', 'or', \"'\", 'unrotated', 'projectiles', \"'\", 'as', 'they', 'were', 'called', 'could', 'the', 'used', 'for', 'anti', '-', 'aircraft', 'barrages', '.', 'A', '2-inch', 'rocket', 'using', 'HE', 'or', 'wire', 'obstacle', 'warheads', 'was', 'introduced', 'first', 'to', 'deal', 'with', 'low', '-', 'level', 'or', 'dive', 'bombing', 'attacks', 'on', 'smaller', 'targets', 'such', 'as', 'airfields', '.', 'The', '3-inch', 'was', 'in', 'development', 'at', 'the', 'end', 'of', 'the', 'inter', '-', 'war', 'period', '.']\n",
            "['3-inch']\n",
            "___________\n",
            "['What', 'lady', 'in', 'waiting', 'was', 'at', 'the', 'heart', 'of', 'a', '1839', 'court', 'scandal', '?']\n",
            "['At', 'the', 'start', 'of', 'her', 'reign', 'Victoria', 'was', 'popular', ',', 'but', 'her', 'reputation', 'suffered', 'in', 'an', '1839', 'court', 'intrigue', 'when', 'one', 'of', 'her', 'mother', \"'s\", 'ladies', '-', 'in', '-', 'waiting', ',', 'Lady', 'Flora', 'Hastings', ',', 'developed', 'an', 'abdominal', 'growth', 'that', 'was', 'widely', 'rumoured', 'to', 'be', 'an', 'out', '-', 'of', '-', 'wedlock', 'pregnancy', 'by', 'Sir', 'John', 'Conroy', '.', 'Victoria', 'believed', 'the', 'rumours', '.', 'She', 'hated', 'Conroy', ',', 'and', 'despised', '\"', 'that', 'odious', 'Lady', 'Flora', '\"', ',', 'because', 'she', 'had', 'conspired', 'with', 'Conroy', 'and', 'the', 'Duchess', 'of', 'Kent', 'in', 'the', 'Kensington', 'System', '.', 'At', 'first', ',', 'Lady', 'Flora', 'refused', 'to', 'submit', 'to', 'a', 'naked', 'medical', 'examination', ',', 'until', 'in', 'mid', '-', 'February', 'she', 'eventually', 'agreed', ',', 'and', 'was', 'found', 'to', 'be', 'a', 'virgin', '.', 'Conroy', ',', 'the', 'Hastings', 'family', 'and', 'the', 'opposition', 'Tories', 'organised', 'a', 'press', 'campaign', 'implicating', 'the', 'Queen', 'in', 'the', 'spreading', 'of', 'false', 'rumours', 'about', 'Lady', 'Flora', '.', 'When', 'Lady', 'Flora', 'died', 'in', 'July', ',', 'the', 'post', '-', 'mortem', 'revealed', 'a', 'large', 'tumour', 'on', 'her', 'liver', 'that', 'had', 'distended', 'her', 'abdomen', '.', 'At', 'public', 'appearances', ',', 'Victoria', 'was', 'hissed', 'and', 'jeered', 'as', '\"', 'Mrs.', 'Melbourne', '\"', '.']\n",
            "['Lady', 'Flora', 'Hastings']\n",
            "___________\n",
            "['How', 'far', 'do', 'penguins', 'travel', 'when', 'they', 'migrate', '?']\n",
            "['Bird', 'migration', 'is', 'not', 'limited', 'to', 'birds', 'that', 'can', 'fly', '.', 'Most', 'species', 'of', 'penguin', '(', 'Spheniscidae', ')', 'migrate', 'by', 'swimming', '.', 'These', 'routes', 'can', 'cover', 'over', '1,000', 'km', '(', '620', 'mi', ')', '.', 'Dusky', 'grouse', 'Dendragapus', 'obscurus', 'perform', 'altitudinal', 'migration', 'mostly', 'by', 'walking', '.', 'Emus', 'Dromaius', 'novaehollandiae', 'in', 'Australia', 'have', 'been', 'observed', 'to', 'undertake', 'long', '-', 'distance', 'movements', 'on', 'foot', 'during', 'droughts', '.']\n",
            "['over', '1,000', 'km']\n",
            "___________\n",
            "['At', 'what', 'location', 'was', 'the', '\"', 'Flying', 'Chair', '\"', 'installed', 'in', '1845', '?']\n",
            "['In', '1845', ',', 'the', 'Neapolitan', 'architect', 'Gaetano', 'Genovese', 'installed', 'in', 'the', 'Royal', 'Palace', 'of', 'Caserta', 'the', '\"', 'Flying', 'Chair', '\"', ',', 'an', 'elevator', 'ahead', 'of', 'its', 'time', ',', 'covered', 'with', 'chestnut', 'wood', 'outside', 'and', 'with', 'maple', 'wood', 'inside', '.', 'It', 'included', 'a', 'light', ',', 'two', 'benches', 'and', 'a', 'hand', 'operated', 'signal', ',', 'and', 'could', 'be', 'activated', 'from', 'the', 'outside', ',', 'without', 'any', 'effort', 'on', 'the', 'part', 'of', 'the', 'occupants', '.', 'Traction', 'was', 'controlled', 'by', 'a', 'motor', 'mechanic', 'utilizing', 'a', 'system', 'of', 'toothed', 'wheels', '.', 'A', 'safety', 'system', 'was', 'designed', 'to', 'take', 'effect', 'if', 'the', 'cords', 'broke', '.', 'It', 'consisted', 'of', 'a', 'beam', 'pushed', 'outwards', 'by', 'a', 'steel', 'spring', '.']\n",
            "['Royal', 'Palace', 'of', 'Caserta']\n",
            "___________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBFLHW9CvTTd",
        "outputId": "e73bc3e6-0f9a-432e-a595-3d7eca24031f"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBy0rc85sDyu"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data), sort = False,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4q5axNJ6O_S"
      },
      "source": [
        "# print(len(valid_iterator))\n",
        "# for i in valid_iterator:\n",
        "#   print(i.context[0].shape)\n",
        "#   print(i.question[0].shape)\n",
        "#   print(i.answer[0].shape)\n",
        "#   break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4W-rfx1vI9Q"
      },
      "source": [
        "# for n, i in enumerate(train_iterator):\n",
        "#   print(i.context[0].shape)\n",
        "#   print(i.question[0].shape)\n",
        "#   print(i.answer[0].shape)\n",
        "#   print(\"------------------\")\n",
        "#   if n == 10:\n",
        "#     break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "Zyl30ao_Wmjc",
        "outputId": "2b632fb0-1597-4ad6-96f9-bd8670d53abe"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('att_seq2seq.jpg', width=700, height=400)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "att_seq2seq.jpg",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 700,
              "height": 400
            }
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWFZgX3XWrnM"
      },
      "source": [
        "The above figure is abasic attention model with single encoder in a seq to seq model.\n",
        "Block(A) will give the probability values for the input source length, which will be multiplied in Block(W) with theactual output vectors of the sourse sentence(one vertor for each time step), to give corresponding attention weightage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojvXj5g8WuHe"
      },
      "source": [
        "Sinse the QA model needs to take in two inputs(context and question). we need to provide two encoders with two source lenths.\n",
        "The below figure is an attemp to use double encoder attention."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "ZPwsleADXDhD",
        "outputId": "f02f9322-5ae5-4b59-dfed-fe5ca8aa1754"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('att_1_seq2seq.jpg', width=1000, height=600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "att_1_seq2seq.jpg",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 1000,
              "height": 600
            }
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQWNb-2TXWbB"
      },
      "source": [
        "Here the Decoder hidden vector will be repeated for the total of src_len + src_q_len times. Which is sum of source lengths of context and the question.\n",
        "Here the attention is applied on all the source inputs together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn2M6vfnXqOL"
      },
      "source": [
        "The dimentions specified in the code at every stage reflect the new dimentions of double encoder seen above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsDU6tq40mEa"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "                \n",
        "        #outputs = [src len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs are always from the last layer\n",
        "        \n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        #  encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UyHjum-WxqZ"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, encoder_q_outputs):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        src_q_len = encoder_q_outputs.shape[0]\n",
        "        \n",
        "        #repeat decoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len+src_q_len, 1)\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        encoder_q_outputs = encoder_q_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden = [batch size, src q len + src len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        #encoder_q_outputs = [batch size, src q len, enc hid dim * 2]\n",
        "\n",
        "        src_q_c = torch.cat((encoder_outputs,encoder_q_outputs), dim = 1)\n",
        "\n",
        "        #src_q_c = [batch size, src q len + src len, enc hid dim * 2]\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, src_q_c), dim = 2))) \n",
        "        \n",
        "        #energy = [batch size, src q len + src len, dec hid dim]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        #attention= [batch size, src q len + src len]\n",
        "        \n",
        "        return F.softmax(attention, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jywphfT6DrHK"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, encoder_outputs_q):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, encoder_outputs_q)\n",
        "                \n",
        "        #a = [batch size, src q len + src len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src q len + src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        encoder_outputs_q = encoder_outputs_q.permute(1, 0, 2)\n",
        "\n",
        "        encoder_outputs = torch.cat((encoder_outputs, encoder_outputs_q), dim = 1)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src q len + src len, enc hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJjsZwruDzDh"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, encoder_q, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.encoder_q = encoder_q\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, src_1, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "        \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        encoder_outputs_q, hidden_q = self.encoder_q(src_1)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden = self.decoder(input, hidden, encoder_outputs, encoder_outputs_q)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtqEmjdPD1Sa"
      },
      "source": [
        "INPUT_DIM = len(Context.vocab)\n",
        "INPUT_DIM_Q = len(Question.vocab)\n",
        "OUTPUT_DIM = len(Answer.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "enc_q = Encoder(INPUT_DIM_Q, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Seq2Seq(enc, enc_q, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVXCqFVUngod",
        "outputId": "41da85a0-ff7a-4270-a912-5317edc67ec5"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(97315, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (encoder_q): Encoder(\n",
              "    (embedding): Embedding(21052, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(18037, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=18037, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vahcAmR8ESX8",
        "outputId": "3943a5b9-bda0-434e-c82c-5a7814399c54"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 76,583,285 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyuY9ozfES-2"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKAWoK4qEUbs"
      },
      "source": [
        "TRG_PAD_IDX = Answer.vocab.stoi[Answer.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHagcLxHGBNO",
        "outputId": "a1b789d6-ae61-4854-c21e-3c580fc0ebfd"
      },
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "  print(batch.context[0].T.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([351, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjZtaUix6mYl",
        "outputId": "05706aae-3118-48f2-e99b-11c375272174"
      },
      "source": [
        "for i, batch in enumerate(valid_iterator):\n",
        "  print(batch.context[0].T.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([338, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cdhCVdqE2Ke"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.context[0].T\n",
        "        src_1 = batch.question[0].T\n",
        "        trg = batch.answer[0].T\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # print(src.shape, trg.shape)\n",
        "        output = model(src, src_1, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].reshape(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P6BdqawFcjY"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            # src = batch.src.T\n",
        "            # trg = batch.trg.T\n",
        "            src = batch.context[0].T\n",
        "            src_1 = batch.question[0].T\n",
        "            trg = batch.answer[0].T\n",
        "\n",
        "            output = model(src, src_1, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].reshape(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3TMAYEHFVes"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "sUOXaSIRFYz6",
        "outputId": "dd7b5646-8a6f-47c4-9337-310cbbf6d569"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 9m 2s\n",
            "\tTrain Loss: 7.133 | Train PPL: 1252.181\n",
            "\t Val. Loss: 6.294 |  Val. PPL: 541.569\n",
            "Epoch: 02 | Time: 9m 1s\n",
            "\tTrain Loss: 5.926 | Train PPL: 374.629\n",
            "\t Val. Loss: 5.858 |  Val. PPL: 350.059\n",
            "Epoch: 03 | Time: 9m 3s\n",
            "\tTrain Loss: 4.728 | Train PPL: 113.018\n",
            "\t Val. Loss: 5.856 |  Val. PPL: 349.490\n",
            "Epoch: 04 | Time: 9m 2s\n",
            "\tTrain Loss: 3.551 | Train PPL:  34.851\n",
            "\t Val. Loss: 6.243 |  Val. PPL: 514.535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-3bf4a897e97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-593f062594bb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 82.00 MiB (GPU 0; 15.75 GiB total capacity; 13.41 GiB already allocated; 52.88 MiB free; 14.48 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE1BiP6wFtsV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}